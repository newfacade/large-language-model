{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75662554-667e-4c4a-96eb-aa422b998778",
   "metadata": {},
   "source": [
    "# WizardLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d0293-bf75-4d7e-95bf-dc97fd567c43",
   "metadata": {},
   "source": [
    "By using open-domain instruction data generated by real human users, OpenAI’s LLMs have achieved great success. However, the whole annotating process is extremely expensive and time-consuming, on the other hand, the difficulty level distribution of human-created instructions is skewed towards being easy or moderate, with fewer difficult ones.\n",
    "\n",
    "In this work, we introduce Evol-Instruct, a novel method using LLMs instead of humans to automatically\n",
    "mass-produce open-domain instructions of various difficulty levels.\n",
    "\n",
    "![](images/wizardlm1.png)\n",
    "\n",
    "Starting from a simple initial instruction\n",
    "“1+1=?”, our method randomly selects In-depth Evolving (blue direction line) or In-breadth\n",
    "Evolving (red direction line) to upgrade the simple instruction to a more complex one or create a new\n",
    "one (to increase diversity). The In-depth Evolving includes five types of operations: add constraints,\n",
    "deepening, concretizing, increase reasoning steps, and complicate input. The In-breadth Evolving generating a completely new instruction based on the given instruction. These six operations are implemented by prompting an LLM with specific prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0954882-0a2d-4cbd-8df3-da3a2e8b283e",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "We start the evolution from a given initial instruction dataset $D^{(0)} = (I^{(0)}_{k}, R^{(0)}_{k})_{1\\le k\\le N}$, where $I^{(0)}_{k}$ is the $k$-th instruction in $D^{(0)}$, $R^{(0)}_{k}$ is the corresponding response for the $k$-th instruction, and $N$ is the number of samples in $D^{(0)}$.\n",
    "\n",
    "In each evolution, we upgrade all the $I^{(t)}$ in $D^{(t)}$ to $I^{(t+1)}$ by applying a\n",
    "LLM instruction evolution prompt, and then use the LLM to generate corresponding responses $R^{(t+1)}$ for the newly evolved $I^{(t+1)}$. Thus, we obtain an evolved instruction dataset $D^{(t+1)}$\n",
    "\n",
    "![](images/wizardllm2.png)\n",
    "\n",
    "**Prompts of In-Depth Evolving.** e.g. add constraints:\n",
    "\n",
    "    I want you act as a Prompt Rewriter.\n",
    "    Your objective is to rewrite a given prompt into a more complex version to make those famous AI systems\n",
    "    (e.g., ChatGPT and GPT4) a bit harder to handle.\n",
    "    But the rewritten prompt must be reasonable and must be understood and responded by humans.\n",
    "    Your rewriting cannot omit the non-text parts such as the table and code in #Given Prompt#:. Also, please\n",
    "    do not omit the input in #Given Prompt#.\n",
    "    You SHOULD complicate the given prompt using the following method:\n",
    "    Please add one more constraints/requirements into #Given Prompt#\n",
    "    You should try your best not to make the #Rewritten Prompt# become verbose, #Rewritten Prompt# can only\n",
    "    add 10 to 20 words into #Given Prompt#.\n",
    "    ‘#Given Prompt#’, ‘#Rewritten Prompt#’, ‘given prompt’ and ‘rewritten prompt’ are not allowed to appear in\n",
    "    #Rewritten Prompt#\n",
    "    #Given Prompt#:\n",
    "    <Here is instruction.>\n",
    "    #Rewritten Prompt#:\n",
    "    \n",
    "**Prompts of In-Breadth Evolving.**\n",
    "\n",
    "    I want you act as a Prompt Creator.\n",
    "    Your goal is to draw inspiration from the #Given Prompt# to create a brand new prompt.\n",
    "    This new prompt should belong to the same domain as the #Given Prompt# but be even more rare.\n",
    "    The LENGTH and difficulty level of the #Created Prompt# should be similar to that of the #Given Prompt#.\n",
    "    The #Created Prompt# must be reasonable and must be understood and responded by humans.\n",
    "    ‘#Given Prompt#’, ‘#Created Prompt#’, ‘given prompt’ and ‘created prompt’ are not allowed to appear in\n",
    "    #Created Prompt#.\n",
    "    #Given Prompt#:\n",
    "    <Here is instruction.>\n",
    "    #Created Prompt#:\n",
    "    \n",
    "**Response Generation.** We use the same LLM as for evolving to generate the corresponding\n",
    "responses for the evolved instructions.\n",
    "    \n",
    "**Elimination Evolving.** \n",
    "1. The evolved instruction does not provide any information gain compared to the original one.\n",
    "We use ChatGPT to make this determination\n",
    "2. The evolved instruction makes it difficult for the LLM to generate a response. We found that\n",
    "when the generated response contains “sorry” and is relatively short in length, it often indicates that the LLM struggles to respond to the evolved instruction.\n",
    "So we can use this rule to make a judgment.  \n",
    "3. The response generated by the LLM only contains punctuation and stop words.\n",
    "4. The evolved instruction obviously copies some words from the evolving prompt, such as\n",
    "“given prompt”, “rewritten prompt”, “#Rewritten Prompt#”, etc.\n",
    "\n",
    "**Finetuning the LLM on the Evolved Instructions.** Once all evolutions are done, we will `merge` the initial instruction dataset with evolved instruction\n",
    "data from all epochs and randomly shuffle the samples to create the final fine-tuning dataset. This\n",
    "processing ensures even distribution of instructions of varying difficulty levels in the dataset, maximizing\n",
    "model fine-tuning smoothness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad347c-9280-40e9-a781-ef4e9df02b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}